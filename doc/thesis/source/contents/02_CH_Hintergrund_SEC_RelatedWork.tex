\section{Related Work}\label{ssec:relatedWork}

Im Folgenden werden Arbeiten vorgestellt, die Relevanz für das Thema oder sonstigen Einfluss auf diese Arbeit haben.

\subsection{Allgemeines}\label{ssec:relatedCommon}

Ein Ansatz, der zwar nicht speziell für \ac{XSS}-Angriffe entwickelt wurde, jedoch für die Generierung von solchen Angriffen verwendet werden kann, ist das Open Source Projekt ``Dharma'' \cite{Diehl2015}. Durch die Verwendung einer kontextfreien Konstruktionsgrammatik generiert die Anwendung zufällig aufgebaute Eingaben. Während dieser Masterthesis wurde eine \ac{XSS}-Grammatikdefinition für Dharma entwickelt \cite{Borgardt2017} und dem Open Source Projekt hinzugefügt, sodass ein direkter Vergleich der generierten \ac{XSS}-Payloads erstellt werden kann.

Hai-Feng Guo und Zongyan Qiu entwickelten einen weiteren grammatikbasierten Algorithmus für Testfälle \cite{Eds2013}. Dieser beschäftigte sich mit den Wahrscheinlichkeiten von Endlosschleifen bei der Generierung von Testfällen. Die Autoren verwendeten hierbei zwei Vorgehensweisen. Zum Einen wird bei jeder Rekursion die Wahrscheinlichkeit neu verteilt, sodass es weniger wahrscheinlich ist, den selben Programmpfad wiederholt zu betreten. Hierbei wird jede Rekursion in einer globalen Tabelle aufgezeichnet. Zum Anderen werden Abdeckungsbäume verwendet, um eine Terminierung sicherzustellen.

Des Weiteren gibt es eine Arbeit von Ravichandhran Madhavan et al., welche sich mit dem Vergleich und dem semantischen Prüfen von kontextfreien Grammatiken beschäftigt \cite{Madhavan2015}. Der entwickelte Algorithmus zum Bestimmen von Gleichheit bzw. zum Auffinden von Diskrepanzen wurde als Bestandteil eines Nachhilfe-Systems implementiert. Das Nachhilfe-System diente als automatisches Bewertungssystem von kontextfreien Grammatiken. In der Evaluation des Systems konnte das System 95\% der eingereichten Grammatiken automatisch auswerten - davon 74\% widerlegen und 21\% als valide einstufen. Die übrigen 5\% der eingereichten Grammatiken konnte das Programm nicht automatisch auswerten.

Shay Artzi et al. erarbeiteten eine Möglichkeit, Fehler in Webapplikationen zu finden, indem Sie dynamische Testfälle generierten \cite{Artzi2010}. Dabei suchten die Autoren zwei Fehlerarten: Fehler während der Ausführung (``execution failures'') und HTML-Fehler. Als Ausführungsfehler werden hierbei Fehler bezeichnet, die serverseitig geschehen und die ordnungsgemäße Ausführung des Programms be- oder verhindern. HTML-Fehler hindern zwar nicht den Ablauf der Applikation, führen jedoch dazu, dass der Browser die Webseite nicht korrekt interpretieren und darstellen kann. Im Rahmen ihres Projekts entwickelten die Autoren eine Anwendung auf Basis des PHP-Interpreters, der selbstständig Eingaben generiert und an die Webseite sendet. Im Anschluss wird die Antwort der Webseite ausgewertet und der Webseitenstatus (Datenbank, Session und Cookies) zurückgesetzt. Auf Basis der ausgewerteten Antworten werden neue Testfälle generiert.

P.-C. Héam et al. entwickelten ``Seed'', ein in Java geschriebenes Programm zur Generierung von rekursiven Datenstrukturen \cite{Heam2011}. Die Generierungsgrammatik wird als XML beschrieben und dem Programm übergeben. Danach generiert die Software einen oder mehrere Datensätze. Hierbei kann die Höhe der generierten Grammatikbäume festgelegt werden.

Einen präventiven Ansatz, um \ac{XSS}-Angriffe während der Entwicklung vorzubeugen, erarbeiteten Shahriar et al. in ihrer Arbeit ``MUTEC: Mutation-based testing of cross site scripting'' \cite{Shahriar2009}. Die entwickelte Software ``MUTEC'' testet anhand von definierten Operatoren den Quellcode von Webseiten auf \ac{XSS}-Schwachstellen. Hierbei wird der Quelltext auf spezielle Quellcode-Fragmente durchsucht und durch die Operatoren abgeändert. Auf diesem Weg lassen sich laut den Autoren Schwachstellen ermitteln, bevor die Webseite veröffentlicht wird.

Ein cloud-basiertes Verfahren, um Testing-Tools zu prüfen, haben Krishnaveni et al. entwickelt \cite{Krishnaveni2017}. Unter anderem wurden Softwarelösungen wie die Burp Suite und ZAP (Zed Attack Proxy Project) getestet. Evaluiert wurden die Resultate mittels eines Cloud Test Manager Frameworks, das die Amazon Web Service API verwendet. Die Ergebnisse wurden anhand der erfolgreichen Payloads im Vergleich zur gesendeten Anzahl von Payloads berechnet.

\newpage
\subsection{\ac{XSS}-Angriffe und Mutation}\label{sec:attacksAndMutation}

Hydara et al. haben im Jahr 2014 eine Übersicht über Veröffentlichungen mit dem Thema \ac{XSS} veröffentlicht \cite{Hydara2015a}. In diese Auswertung wurden 115 Studien aus verschiedenen Quellen zum Thema \ac{XSS} aus dem Zeitraum 2000 bis 2012 einbezogen. Die Autoren kamen zu dem Ergebnis, dass im Bereich \ac{XSS} noch sehr aktiv geforscht wird.

Eine Einführung in das Thema \ac{XSS}-Attacken bietet die Arbeit von D. Endler \cite{Endler2002}. Darin beschreibt er insbesondere die Gefahr von reflektierten \ac{XSS}-Attacken anhand eines Session-Hijacking-Angriffs. Insbesondere erläutert er die Gefahren von reflektierten \ac{XSS}-Angriffen und den Möglichkeiten, diese gegen andere Benutzer zu nutzen.

In seiner Arbeit entwickelte Khalil Bijjou ein Kommandozeilenprogramm WAFNinja, welches verschiedene Payloads an eine Webseite schickt und auswertet \cite{Bijjou2015}. Anschließend werden die Angriffe anhand der zurückgelieferten Antworten ausgewertet. Unter anderem wird so ermittelt, welche Zeichen durch die \ac{WAF} herausgefiltert werden, um die nächsten Angriffe zu optimieren.

SecuBat \cite{Kals2006} von Kals et al. ist ebenfalls eine Anwendung, um Angriffe gegen eine von einer \ac{WAF} geschützten Webseite zu fahren. Diese Software gliedert sich in drei Komponenten (\gls{Crawler}-, Angriff- und Analyse-Modul). Verwendete \ac{XSS}-Payloads werden jedoch durch Kodierung in beispielsweise Hexadezimal verschleiert. Für die Angriffskomponente haben die Autoren zwei Plugins für jeweils \ac{XSS}- und SQL-Injections entwickelt. Die Antwort der Webseite wird bei Rückmeldung auf bestimmte Stichwörter (Fehlermeldungen bei SQL-Injections) bzw. den gesendeten Angriff durchsucht.

Vogt et al. verfolgten den Ansatz eine zusätzliche Sicherheitsschicht in den Browser des Benutzers einzubauen, um so den gelieferten Quelltext auf Zugriffe persönlicher oder sicherheitskritischer Daten zu prüfen \cite{Vogt2007}. Hierdurch ließen sich sowohl reflektierte als auch persistente \ac{XSS}-Angriffe abwehren. Die Evaluation wurde mit einem Add-on für den Firefox Browser und über einer Million Webseiten durchgeführt. Von allen aufgerufenen Seiten beinhalteten rund 9\% einen \ac{XSS}-Zugriff, hierbei bestand der größte Teil aus Werbe- und Analyseseiten.

Heiderich et al. beschäftigten sich mit \ac{XSS}-Angriffen unter Verwendung des HTML-Attributs ``innerHtml'', das vor allem häufig in ``\acs{WYSIWYG}''-Texteditoren oder Webmail-Clients verwendet wird \cite{Heiderich2013}. Durch einen Implementierungsfehler in verschiedenen Browsern verschwanden \gls{Backtick}s, wodurch der restliche Quelltext mutierte und so schädlicher Code an den Editor übergeben werden konnte.

Wang et al. entwickelten einen Ansatz zur kombinierten Mutation von \ac{XSS}-Angriffen \cite{Wang2010}. Hierbei verwendeten die Autoren bereits vorhandene, öffentlich zugängliche Angriffe von Seiten wie \url{http://xssed.com/}. Der entwickelte Algorithmus zerlegt zunächst die Angriffe in Einzelteile und generiert so ein Angriffsmodell. Anschließend wird mit einer Abwandlung des ``Viterbi''-Algorithmus \cite{Viterbi1967} ein neuer \ac{XSS}-Angriff generiert. Der Viterbi-Algorithmus ermöglicht zum Beispiel die Berechnung der kürzesten Distanz aus einer Menge an Knoten.

Tripp et al. entwickelten einen lernenden Algorithmus, welcher sich aus mehr als 500.000.000 \ac{XSS}-Angriffen immer passendere Angriffe wählen kann \cite{Tripp2013}. In ihrer Ausarbeitung erläutern die Autoren, dass es grundlegend zwei Wege gibt einen \gls{Sanitizer} zu umgehen. Entweder ist die WAF inkorrekt, sodass ein Angriff nicht als solcher erkannt wird, oder es gibt eine Eingabe, die durch die Veränderung des WAF zu einem validen (erfolgreichen) \ac{XSS}-Angriff umgewandelt wird. Der Lernprozess des Algorithmus gleicht die Antworten der Webseite mit den gesendeten Angriffen ab. Wird beispielsweise das Wort ``script'' von der WAF entfernt, werden zukünftig nur noch Angriffe ohne diese Elemente gewählt.

Eine Methode, um JavaScript-Quellcode an \ac{WAF} vorbei zu schmuggeln, beschreibt Lupac in seiner Arbeit \cite{Luptak2011}. Hierbei wird funktionsfähiger JavaScript-Quelltext aus den Grundbestandteilen der Sprache konstruiert. Anhand eines Beispiels konstruierte Lupac den Befehl ``alert(1)'' aus den sechs Zeichen ``['', ``]'', ``('', ``)'', ``!'' und ``+''. Mittlerweile gibt es für diese Art von Verschleierungstaktik eigene Implementierungen, wie zum Beispiel ``JSFuck'' \cite{Kleppe} oder ``6charsJS'' \cite{Pollet-Villard2016}.

\subsection{Grammatik-basierte Ansätze}\label{ssec:grammar-based-approaches}

LigRE ist ein Reverse-Engineering-Ansatz, der die zu testende Webseite analysiert und die Wege der Datenströme ermittelt \cite{Duchene2013}. Zusätzlich werden besonders Erfolg versprechende Pfade und \ac{XSS}-Angriffe priorisiert und somit verstärkt verwendet.

Mit KameleonFuzz haben Duchene et al. einen grammatik-basierten Ansatz entwickelt \cite{Duchene2014}, der unter Verwendung ihres Reverse-Engineering Ansatzes die generierten \gls{payload}s bewerten und entsprechend anpassen kann. Die Ausarbeitung umfasst neben dem Finden von erfolgreichen Angriffen auch das Erkennen von sogenannten ``Macro-States'', welche einen veränderten globalen Status der Webseite beschreiben. Diese sind vor allem eine wichtige Komponente der persistenten \acl{XSS}-Attacken.

Einen auf KameleonFuzz aufgebauten Ansatz haben Wies et. al.  ausgearbeitet \cite{Wies2014}. In dieser Arbeit werden die generierten Angriffe als Gene bezeichnet und anhand einer ``Fitness''-Funktion bewertet. Ein Teil dieser ``Fitness'' wird durch das Zählen von bestimmten, für HTML- bzw. JavaScript-Code wichtiges Zeichen berechnet. Hierzu wird für jedes enthaltene Zeichen die Fitness des Angriffsmusters erhöht. Welche weiteren Kriterien für die ``Fitness'' ausschlaggebend sind, wird hingegen nicht weiter erwähnt.

Bozic et al. verwendeten in ihrem Ansatz eine \ac{UML} gestützte Vorgehensweise \cite{Bozic}. Zur Generierung der Angriffe wird die Angriffsgrammatik von Duchene et. al. mit zusätzlichen Bedingungen verwendet \cite{Duchene2013a}. Dies hat in der Arbeit von Bozic die Wahrscheinlichkeit auf erfolgreiche Angriffe deutlich verbessert.